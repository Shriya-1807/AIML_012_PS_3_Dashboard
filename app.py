# -*- coding: utf-8 -*-
"""app.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1P8d84K3HrE8bySVIucRiJ6uNHPUVcHIa
"""

import streamlit as st
import numpy as np
import tempfile
import os
import cv2
from PIL import Image
from collections import Counter
import time
import torch
import uuid
import shutil

from ultralytics import YOLOWorld
from sahi.predict import get_sliced_prediction
from sahi.models.ultralytics import UltralyticsDetectionModel
from deep_sort_realtime.deepsort_tracker import DeepSort

# Streamlit Page Config
st.set_page_config(page_title='Drone Detector', page_icon='üöÄ', layout='wide')

# Styling
st.markdown("""
    <style>
        .main {max-height: 100vh; overflow-y: scroll;}
        .block-container {padding-top: 0rem !important; margin-top: 0rem !important;}
        .title {font-size: 15px; font-family: Georgia, serif; text-align: center; }
        section[data-testid="stSidebar"] {
            background:linear-gradient(to bottom , #0F202B, #202D4A, #172626);
            padding: 20px;
            border-right: 2px solid #FFFFFF;
            font-family: Verdana, sans-serif;
            font-size: 16px;
            width: 300px !important;
        }
        div[data-testid="stSidebarContent"] {width: 100% !important;}
        main{background: linear-gradient(to bottom right, #0F202B, #020229 );padding: 10px;}
    </style>
""", unsafe_allow_html=True)

st.markdown('<h1 class="title">Drone Footage Object Detection and Tracking</h1>', unsafe_allow_html=True)

# Sidebar

selected_model = st.sidebar.radio(
    label="Select",
    options=["Default Detection","Text-prompt Detection"],
    index=0,
    help="Choose the model to use for object detection."
)

confidence_value = st.sidebar.slider("Select model confidence value", min_value=0.1, max_value=1.0, value=0.25, step=0.05)

model_path = "last.pt"
text_prompt_model_path = "yolov8l-worldv2.pt"

category_names = []
if selected_model == "Text-prompt Detection":
    st.sidebar.markdown("---")
    st.sidebar.markdown("**Text Prompt Settings**")
    user_prompts = st.sidebar.text_input(
        "Enter class names (separated by comma):",
        help="Enter the objects you want to detect, separated by commas"
    )
    category_names = [x.strip() for x in user_prompts.split(",") if x.strip() != ""]
    
    if category_names:
        st.sidebar.write("**Classes to detect:**")
        for i, name in enumerate(category_names, 1):
            st.sidebar.write(f"{i}. {name}")

# Image
st.markdown(
    '<p style="font-size:22px; font-family:\'Segoe UI\', sans-serif; font-weight:bold; color:#8cc8e6; margin-top:2px;">üì∏ Upload a drone image</p>',
    unsafe_allow_html=True
)
uploaded_image = st.file_uploader("Upload Image", type=['jpg', 'jpeg', 'png', 'webp'], key="img_upload") 


def run_sahi_yolo_inference(image_pil, model_path, conf):
    image_np = np.array(image_pil.convert("RGB"))
    detection_model = UltralyticsDetectionModel(
        model_path=model_path,
        confidence_threshold=conf,
        device="cuda:0" if torch.cuda.is_available() else "cpu"
    )
    result = get_sliced_prediction(
        image_np,
        detection_model,
        slice_height=512,
        slice_width=512,
        overlap_height_ratio=0.2,
        overlap_width_ratio=0.2
    )
    return result
def run_text_prompt_sahi_inference(image_pil, model_path, conf, category_names):
    """Text prompt SAHI inference with your colab settings"""
    image_np = np.array(image_pil.convert("RGB"))
    
    
    model = YOLOWorld(text_prompt_model_path)
    model.set_classes(category_names)
    
    detection_model = UltralyticsDetectionModel(
        model_path=text_prompt_model_path,
        confidence_threshold=conf,
        device="cuda:0" if torch.cuda.is_available() else "cpu"
    )
    
    
    result = get_sliced_prediction(
        image_np,
        detection_model,
        slice_height=256,  # Using your colab settings
        slice_width=256,
        overlap_height_ratio=0.3,
        overlap_width_ratio=0.3
    )
    return result



if uploaded_image is not None:
    image = Image.open(uploaded_image)
    st.markdown("### üñºÔ∏è Uploaded Image Preview")
    st.image(image, caption="Uploaded Image", use_container_width=True)

    
    if selected_model == "Text-prompt Detection" and category_names:
        st.info(f"**Detecting:** {', '.join(category_names)}")
    elif selected_model == "Text-prompt Detection" and not category_names:
        st.warning(" Please enter class names in the sidebar for text prompt detection!")
        st.stop()

    with st.spinner("Running SAHI tiled inference..."):
        try:
            if selected_model == "Default Detection":
                result = run_sahi_yolo_inference(image, model_path, confidence_value)
            else:  
                result = run_text_prompt_sahi_inference(image, text_prompt_model_path, confidence_value, category_names)
            
            unique_img_name = f"result_{uuid.uuid4().hex}"
            output_dir = os.path.abspath("outputs")
            os.makedirs(output_dir, exist_ok=True)
            result_img_path = os.path.join(output_dir, f"{unique_img_name}.png")

            try:
                result.export_visuals(
                    export_dir = output_dir,   
                    file_name=unique_img_name,
                    text_size=0.5,
                    rect_th=1,
                    hide_labels=False,
                    hide_conf=True,
                )
                time.sleep(1)
            
                st.success("Inference done and Image exported successfully!")
            except Exception as e:
                st.error(f"Failed to export result visualization: {e}")
                result_img_path = None
        
        except Exception as e:
             st.error(f"Error during inference: {e}")
             result_img_path = None
    
    if result_img_path and os.path.exists(result_img_path):
        st.markdown("### üéØ Detected Output")
        with open(result_img_path, 'rb') as f:
            img_bytes = f.read()
        st.image(img_bytes, caption="Detected with SAHI", use_container_width=True)
        
        st.download_button(
            label="üì• Download Annotated Image",
            data=img_bytes,
            file_name=os.path.basename(result_img_path),
            mime="image/jpeg"
        )
        
        st.markdown("### üìä Object Counts")
        class_names = [pred.category.name for pred in result.object_prediction_list]
        class_counts = Counter(class_names)
        for cls, count in class_counts.items():
            st.markdown(f"- **{cls}**: {count}")

    else:
        st.error("‚ùå Exported image not found.")
    
