# -*- coding: utf-8 -*-
"""app.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1P8d84K3HrE8bySVIucRiJ6uNHPUVcHIa
"""

import streamlit as st
import numpy as np
import tempfile
import os
import cv2
from PIL import Image
from collections import Counter
import time
import torch
import uuid
import shutil

from ultralytics import YOLOWorld
from sahi.predict import get_sliced_prediction
from sahi.models.ultralytics import UltralyticsDetectionModel
from deep_sort_realtime.deepsort_tracker import DeepSort

# Streamlit Page Config
st.set_page_config(page_title='Drone Detector', page_icon='üöÄ', layout='wide')

# Styling
st.markdown("""
    <style>
        .main {max-height: 100vh; overflow-y: scroll;}
        .block-container {padding-top: 0rem !important;}
        .title {font-size: 20px; font-family: Georgia, serif; text-align: center; margin-top: 3px;}
        section[data-testid="stSidebar"] {
            background:linear-gradient(to bottom , #0F202B, #202D4A, #172626);
            padding: 20px;
            border-right: 2px solid #FFFFFF;
            font-family: Verdana, sans-serif;
            font-size: 16px;
            width: 300px !important;
        }
        div[data-testid="stSidebarContent"] {width: 100% !important;}
        main{background: linear-gradient(to bottom right, #0F202B, #020229 );padding: 10px;}
    </style>
""", unsafe_allow_html=True)

st.markdown('<h1 class="title">Drone Footage Object Detection and Tracking</h1>', unsafe_allow_html=True)

# Sidebar

selected_model = st.sidebar.radio(
    label="Select",
    options=["Default Detection","Text-prompt Detection"],
    index=0,
    help="Choose the model to use for object detection."
)

confidence_value = st.sidebar.slider("Select model confidence value", min_value=0.1, max_value=1.0, value=0.25, step=0.05)

model_path = "last.pt"

# Image
st.markdown(
    '<p style="font-size:22px; font-family:\'Segoe UI\', sans-serif; font-weight:bold; color:#8cc8e6; margin-top:5px;">üì∏ Upload a drone image</p>',
    unsafe_allow_html=True
)
uploaded_image = st.file_uploader("Upload Image", type=['jpg', 'jpeg', 'png', 'webp'], key="img_upload") 


def run_sahi_yolo_inference(image_pil, model_path, conf):
    image_np = np.array(image_pil.convert("RGB"))
    detection_model = UltralyticsDetectionModel(
        model_path=model_path,
        confidence_threshold=conf,
        device="cuda:0" if torch.cuda.is_available() else "cpu"
    )
    result = get_sliced_prediction(
        image_np,
        detection_model,
        slice_height=512,
        slice_width=512,
        overlap_height_ratio=0.2,
        overlap_width_ratio=0.2
    )
    return result

if uploaded_image is not None:
    image = Image.open(uploaded_image)
    st.markdown("### üñºÔ∏è Uploaded Image Preview")
    st.image(image, caption="Uploaded Image", use_container_width=True)

    with st.spinner("Running SAHI tiled inference..."):
        result = run_sahi_yolo_inference(image, model_path, confidence_value)
        unique_img_name = f"result_{uuid.uuid4().hex}"
        output_dir = os.path.abspath("outputs")
        os.makedirs(output_dir, exist_ok=True)
        result_img_path = os.path.join(output_dir, f"{unique_img_name}.jpg")

        try:
            result.export_visuals(
                export_dir = output_dir,   
                file_name=f"{unique_img_name}.jpg",
                text_size=0.5,
                rect_th=1,
                hide_labels=False,
                hide_conf=True,
            )
            time.sleep(1)
            
            st.success("Inference done and Image exported successfully!")
        except Exception as e:
            st.error(f"Failed to export result visualization: {e}")
            result_img_path = None
    if result_img_path and os.path.exists(result_img_path):
        st.markdown("### üéØ Detected Output")
        with open(result_img_path, 'rb') as f:
            img_bytes = f.read()
        st.image(img_bytes, caption="Detected with SAHI", use_container_width=True)
        st.download_button(
            label="üì• Download Annotated Image",
            data=img_bytes,
            file_name=os.path.basename(result_img_path),
            mime="image/jpeg"
        )
    else:
        st.error("‚ùå Exported image not found.")
    

        st.markdown("### üìä Object Counts")
        class_names = [pred.category.name for pred in result.object_prediction_list]
        class_counts = Counter(class_names)
        for cls, count in class_counts.items():
            st.markdown(f"- **{cls}**: {count}")

#Video
st.markdown(
    '<p style="font-size:22px; font-family:\'Segoe UI\', sans-serif; font-weight:bold; color:#8cc8e6; margin-top:30px;">üé• Upload a drone video</p>',
    unsafe_allow_html=True
)
uploaded_video = st.file_uploader("Upload Video", type=['mp4', 'avi', 'mov', 'mkv'], key="vid_upload")

def process_video_with_yolo_deepsort(video_path, output_path, weights_path, skip_frames=2):
    model = YOLOWorld(weights_path)
    tracker = DeepSort(max_age=10)
    
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        st.error(" Could not open the uploaded video. Please try with a different .mp4 file.")
        return None
    
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    fps = cap.get(cv2.CAP_PROP_FPS)

    fourcc = cv2.VideoWriter_fourcc(*"mp4v")
    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))

    frame_count = 0
    prev_tracks = []
    
    while True:
        ret, frame = cap.read()
        if not ret:
            break
        frame_count += 1
        if frame_count % skip_frames == 0:
            results = model.predict(frame, conf=0.25, iou=0.6, augment=False, verbose=False)
            results = results[0]
            detections = []
            for box in results.boxes:
                x1, y1, x2, y2 = map(int, box.xyxy[0].cpu().numpy())
                conf = float(box.conf[0].cpu().numpy())
                cls = int(box.cls[0].cpu().numpy())
                detections.append(([x1, y1, x2 - x1, y2 - y1], conf, cls))
            tracks = tracker.update_tracks(detections, frame=frame)
            prev_tracks = tracks
        else:
            tracks = prev_tracks
        for track in tracks:
            if not track.is_confirmed():
                continue
            l, t, r, b = map(int, track.to_ltrb())
            track_id = track.track_id
            cv2.rectangle(frame, (l, t), (r, b), (0, 255, 0), 2)
            cv2.putText(frame, f"ID: {track_id}", (l, t - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)
        out.write(frame) 
    
    
    cap.release()
    out.release()

    return output_path

if uploaded_video is not None:
    video_dir = os.path.join("outputs")
    os.makedirs(video_dir, exist_ok=True)
    temp_video_path = os.path.join(video_dir, f"{uuid.uuid4()}.mp4")

    with open(temp_video_path, 'wb') as f:
        f.write(uploaded_video.read())
    st.video(temp_video_path)  

    with st.spinner("Processing video..."):

        base, ext = os.path.splitext(temp_video_path)
        temp_output_path = f"{base}_out{ext}"

        try:
            result_video_path = process_video_with_yolo_deepsort(
                temp_video_path,
                output_path=temp_output_path,
                weights_path=model_path,
                skip_frames=2
            )
        except Exception as e:
            st.error(f"‚ö†Ô∏è Video processing failed: {e}")
            result_video_path = None
    
    
        time.sleep(0.5)
        st.success("Video processed!")

        if result_video_path is None:
            st.error("Video processing failed or video could not be opened. Please try with a valid video file.")
        elif os.path.exists(result_video_path) and os.path.getsize(result_video_path) > 1000:
            with open(result_video_path, 'rb') as vid_file:
                vid_bytes = vid_file.read()
            st.video(vid_bytes)
        else:
            st.error("Processed video not found or is empty.")


        if os.path.exists(result_video_path) and os.path.getsize(result_video_path) > 1000:
            with open(result_video_path, 'rb') as vid_file:
                vid_bytes = vid_file.read()
            st.video(vid_bytes)
        else:
            st.error("Processed video not found or is empty.")
          
