# -*- coding: utf-8 -*-
"""app.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1P8d84K3HrE8bySVIucRiJ6uNHPUVcHIa
"""

import streamlit as st
import numpy as np
import tempfile
import os
import cv2
from PIL import Image
from collections import Counter
import time
import torch
import uuid

from ultralytics import YOLOWorld
from sahi.predict import get_sliced_prediction
from sahi.models.ultralytics import UltralyticsDetectionModel
from deep_sort_realtime.deepsort_tracker import DeepSort

# Streamlit Page Config
st.set_page_config(page_title='Drone Detector', page_icon='üöÄ', layout='wide')

# Styling
st.markdown("""
    <style>
        .main {max-height: 100vh; overflow-y: scroll;}
        .block-container {padding-top: 0rem !important;}
        .title {font-size: 20px; font-family: Georgia, serif; text-align: center; margin-top: 3px;}
        section[data-testid="stSidebar"] {
            background:linear-gradient(to bottom , #0F202B, #202D4A, #172626);
            padding: 20px;
            border-right: 2px solid #FFFFFF;
            font-family: Verdana, sans-serif;
            font-size: 16px;
            width: 300px !important;
        }
        div[data-testid="stSidebarContent"] {width: 100% !important;}
        main{background: linear-gradient(to bottom right, #0F202B, #020229 );padding: 10px;}
    </style>
""", unsafe_allow_html=True)

st.markdown('<h1 class="title">Drone Footage Object Detection and Tracking</h1>', unsafe_allow_html=True)

# Sidebar
st.sidebar.title("‚û§ Specifications : ")
st.sidebar.markdown("""
    <p style='font-size:17px; font-weight:bold; font-family:"Segoe UI", sans-serif; color:white;'>
        ‚û§ Select Detection Model
    </p>
""", unsafe_allow_html=True)

selected_model = st.sidebar.radio(
    label="Select Model",
    options=["YOLOv8 s-Worldv2"],
    index=0,
    help="Choose the model to use for object detection."
)

confidence_value = st.sidebar.slider("Select model confidence value", min_value=0.1, max_value=1.0, value=0.25, step=0.05)
iou_value = st.sidebar.slider("Select iou value", min_value=0.1, max_value=1.0, value=0.4, step=0.1)

model_path = "last.pt"

# Image
st.markdown(
    '<p style="font-size:22px; font-family:\'Segoe UI\', sans-serif; font-weight:bold; color:#8cc8e6; margin-top:5px;">üì∏ Upload a drone image</p>',
    unsafe_allow_html=True
)
uploaded_image = st.file_uploader("Upload Image", type=['jpg', 'jpeg', 'png', 'webp'], key="img_upload")

def run_sahi_yolo_inference(image_pil, model_path, conf):
    image_np = np.array(image_pil.convert("RGB"))
    detection_model = UltralyticsDetectionModel(
        model_path=model_path,
        confidence_threshold=conf,
        device="cuda:0" if torch.cuda.is_available() else "cpu"
    )
    result = get_sliced_prediction(
        image_np,
        detection_model,
        slice_height=512,
        slice_width=512,
        overlap_height_ratio=0.2,
        overlap_width_ratio=0.2
    )
    unique_img_name = f"result_{uuid.uuid4().hex}"
    output_dir = os.path.join("outputs")
    os.makedirs(output_dir, exist_ok=True)
    result_img_path = os.path.join(output_dir, f"{unique_img_name}.jpg")

    try:
        result.export_visuals(
            name=unique_img_name,
            text_size=0.5,
            rect_th=1,
            hide_labels=False,
            hide_conf=True,
        )
        shutil.move(f"{unique_img_name}.jpg", result_img_path)

        st.info("Called result.export_visuals and moved image to outputs/")
        except Exception as e:
            st.error(f"Failed to export result visualization: {e}")


        if os.path.exists(result_img_path):
            st.image(Image.open(result_img_path), caption="Detected with SAHI", use_container_width=True)
        else:
            st.error(f"[ERROR] Image not found at path: {result_img_path}")


        if not os.path.exists(result_img_path):
            st.error(f"Export failed: File not created at {result_img_path}")
        else:
            st.success(f"Export succeeded: File created at {result_img_path}")
    except Exception as e:
        st.error(f"Failed to export result visualization: {e}")
        return result_img_path, result
    return result_img_path, result


if uploaded_image is not None:
    image = Image.open(uploaded_image)
    st.markdown("### üñºÔ∏è Uploaded Image Preview")
    st.image(image, caption="Uploaded Image", use_container_width=True)

    with st.spinner("Running SAHI tiled inference..."):
        output_image_path, result = run_sahi_yolo_inference(image, model_path, confidence_value)
        st.success("Inference done!")

        st.markdown("### üéØ Detected Output")
    
        if not os.path.exists(output_image_path):
            st.error(f"Could not find: {output_image_path}")
        else:
            with open(output_image_path, 'rb') as f:
                img_bytes = f.read()
            st.image(img_bytes, caption="Detected with SAHI", use_container_width=True)
        

        st.markdown("### üìä Object Counts")
        class_names = [pred.category.name for pred in result.object_prediction_list]
        class_counts = Counter(class_names)
        for cls, count in class_counts.items():
            st.markdown(f"- **{cls}**: {count}")

#Video
st.markdown(
    '<p style="font-size:22px; font-family:\'Segoe UI\', sans-serif; font-weight:bold; color:#8cc8e6; margin-top:30px;">üé• Upload a drone video</p>',
    unsafe_allow_html=True
)
uploaded_video = st.file_uploader("Upload Video", type=['mp4', 'avi', 'mov', 'mkv'], key="vid_upload")

def process_video_with_yolo_deepsort(video_path, output_path, weights_path, skip_frames=2):
    model = YOLOWorld(weights_path)
    tracker = DeepSort(max_age=10)
    
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        st.error(" Could not open the uploaded video. Please try with a different .mp4 file.")
        return None
    
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    fps = cap.get(cv2.CAP_PROP_FPS)

    fourcc = cv2.VideoWriter_fourcc(*"mp4v")
    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))

    frame_count = 0
    prev_tracks = []
    
    while True:
        ret, frame = cap.read()
        if not ret:
            break
        frame_count += 1
        if frame_count % skip_frames == 0:
            results = model.predict(frame, conf=0.25, iou=0.6, augment=False, verbose=False)
            results = results[0]
            detections = []
            for box in results.boxes:
                x1, y1, x2, y2 = map(int, box.xyxy[0].cpu().numpy())
                conf = float(box.conf[0].cpu().numpy())
                cls = int(box.cls[0].cpu().numpy())
                detections.append(([x1, y1, x2 - x1, y2 - y1], conf, cls))
            tracks = tracker.update_tracks(detections, frame=frame)
            prev_tracks = tracks
        else:
            tracks = prev_tracks
        for track in tracks:
            if not track.is_confirmed():
                continue
            l, t, r, b = map(int, track.to_ltrb())
            track_id = track.track_id
            cv2.rectangle(frame, (l, t), (r, b), (0, 255, 0), 2)
            cv2.putText(frame, f"ID: {track_id}", (l, t - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)
        out.write(frame) 
    
    
    cap.release()
    out.release()

    return output_path

if uploaded_video is not None:
    video_dir = os.path.join("outputs")
    os.makedirs(video_dir, exist_ok=True)
    temp_video_path = os.path.join(video_dir, f"{uuid.uuid4()}.mp4")

    with open(temp_video_path, 'wb') as f:
        f.write(uploaded_video.read())
    st.video(temp_video_path)  

    with st.spinner("Processing video..."):

        base, ext = os.path.splitext(temp_video_path)
        temp_output_path = f"{base}_out{ext}"

        try:
            result_video_path = process_video_with_yolo_deepsort(
                temp_video_path,
                output_path=temp_output_path,
                weights_path=model_path,
                skip_frames=2
            )
        except Exception as e:
            st.error(f"‚ö†Ô∏è Video processing failed: {e}")
            result_video_path = None
    
    
        time.sleep(0.5)
        st.success("Video processed!")

        if result_video_path is None:
            st.error("Video processing failed or video could not be opened. Please try with a valid video file.")
        elif os.path.exists(result_video_path) and os.path.getsize(result_video_path) > 1000:
            with open(result_video_path, 'rb') as vid_file:
                vid_bytes = vid_file.read()
            st.video(vid_bytes)
        else:
            st.error("Processed video not found or is empty.")


        if os.path.exists(result_video_path) and os.path.getsize(result_video_path) > 1000:
            with open(result_video_path, 'rb') as vid_file:
                vid_bytes = vid_file.read()
            st.video(vid_bytes)
        else:
            st.error("Processed video not found or is empty.")
          
